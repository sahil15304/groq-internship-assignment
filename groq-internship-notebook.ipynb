{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5fhDMBHnQlA",
        "outputId": "eaec9f75-95cc-4f4a-ac23-d49e89a24396"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.107.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = 'GROQ_API_KEY_PLACEHOLDER'\n",
        "openai.api_base = \"https://api.groq.com/v1\""
      ],
      "metadata": {
        "id": "qSzadeOgnl34"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversations = [\n",
        "    {\"user\": \"Hey, I need help with my order.\"},\n",
        "    {\"bot\": \"Sure! Can you share your order ID?\"},\n",
        "    {\"user\": \"It's ORD12345.\"},\n",
        "    {\"bot\": \"Thanks! I see your order is being processed and will be shipped soon.\"},\n",
        "    {\"user\": \"Great, also can I change the address?\"},\n",
        "    {\"bot\": \"Yes, you can update the address within 24 hours of placing the order.\"}\n",
        "]\n"
      ],
      "metadata": {
        "id": "LLlqjhtDn1NH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
        "os.environ[\"OPENAI_API_BASE\"] = \"https://api.groq.com/v1\"\n"
      ],
      "metadata": {
        "id": "XkG-zJI3n8CD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "openai.api_base = os.getenv(\"OPENAI_API_BASE\")"
      ],
      "metadata": {
        "id": "LYgiReaYojUw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9umsBdComc3",
        "outputId": "7f7abae7-4748-4379-a533-bbe2a848cd21"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "conversation_text = \"\\n\".join([f\"{list(m.keys())[0]}: {list(m.values())[0]}\" for m in conversations])\n",
        "\n",
        "url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
        "\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"Authorization\": \"Bearer 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\"\n",
        "}\n",
        "\n",
        "data = {\n",
        "    \"model\": \"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
        "    \"messages\": [\n",
        "        {\"role\": \"system\", \"content\": \"You are an assistant that summarizes conversations.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Summarize the following conversation:\\n{conversation_text}\"}\n",
        "    ],\n",
        "    \"max_tokens\": 150\n",
        "}\n",
        "\n",
        "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
        "\n",
        "print(response.status_code)\n",
        "print(response.json())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5Q9eLK3phTJ",
        "outputId": "2e3e280d-b98b-406c-c2c1-03025b2261b4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "{'id': 'chatcmpl-57f7337e-3dd2-4f20-8775-a57812527eab', 'object': 'chat.completion', 'created': 1758128969, 'model': 'meta-llama/llama-4-scout-17b-16e-instruct', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'Here is a summary of the conversation:\\n\\nThe user asked for help with their order, provided the order ID (ORD12345), and was informed that it is being processed and will be shipped soon. They also requested to change the address, and were told that it can be updated within 24 hours of placing the order.'}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'queue_time': 0.186373302, 'prompt_tokens': 103, 'prompt_time': 0.005307896, 'completion_tokens': 66, 'completion_time': 0.160949391, 'total_tokens': 169, 'total_time': 0.166257287}, 'usage_breakdown': None, 'system_fingerprint': 'fp_79da0e0073', 'x_groq': {'id': 'req_01k5cae5gee8crpnz1yg89enfx'}, 'service_tier': 'on_demand'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "conversation_text = \"\\n\".join([f\"{list(m.keys())[0]}: {list(m.values())[0]}\" for m in conversations])\n",
        "\n",
        "url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
        "\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"Authorization\": \"Bearer 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\"\n",
        "}\n",
        "\n",
        "data = {\n",
        "    \"model\": \"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
        "    \"messages\": [\n",
        "        {\"role\": \"system\", \"content\": \"You are an assistant that classifies conversations and extracts structured data like order IDs and issues.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Classify and extract structured information from the following conversation:\\n{conversation_text}\"}\n",
        "    ],\n",
        "    \"max_tokens\": 150\n",
        "}\n",
        "\n",
        "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
        "\n",
        "print(response.status_code)\n",
        "print(response.json()[\"choices\"][0][\"message\"][\"content\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcQTrkm1p9Ip",
        "outputId": "80610d1d-12b7-4f2b-ce53-48d24883e621"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "I can help you classify the conversation and extract structured information. Here's my analysis:\n",
            "\n",
            "**Conversation Classification:** \n",
            "The conversation can be classified as a \"Customer Support\" or \"Order Inquiry\" conversation, specifically related to order status and modification.\n",
            "\n",
            "**Extracted Structured Information:**\n",
            "\n",
            "* **Order ID:** ORD12345\n",
            "* **Order Status:** Being processed, will be shipped soon\n",
            "* **Issue/Request:** Address change request\n",
            "* **Requested Action:** Update shipping address\n",
            "\n",
            "Let me know if you'd like me to extract any further information!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, json, time\n",
        "\n",
        "url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"Authorization\": \"Bearer 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\"\n",
        "}\n",
        "\n",
        "test_conversations = [\n",
        "    [\n",
        "        {\"user\": \"Hi, I want to cancel my subscription.\"},\n",
        "        {\"bot\": \"Sure, share your subscription ID.\"},\n",
        "        {\"user\": \"SUB6789\"},\n",
        "        {\"bot\": \"Cancellation processed.\"}\n",
        "    ],\n",
        "    [\n",
        "        {\"user\": \"My order arrived damaged.\"},\n",
        "        {\"bot\": \"I'm sorry to hear that. Can you send a photo?\"},\n",
        "        {\"user\": \"Sent the photo.\"},\n",
        "        {\"bot\": \"We will replace it and send return instructions.\"}\n",
        "    ],\n",
        "    [\n",
        "        {\"user\": \"What time does your support close?\"},\n",
        "        {\"bot\": \"We operate 24/7.\"}\n",
        "    ],\n",
        "    conversations\n",
        "]\n",
        "\n",
        "results = []\n",
        "for conv in test_conversations:\n",
        "    conversation_text = \"\\n\".join([f\"{list(m.keys())[0]}: {list(m.values())[0]}\" for m in conv])\n",
        "    data = {\n",
        "        \"model\": \"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are an assistant that summarizes, classifies, and extracts structured data from conversations.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Process the following conversation:\\n{conversation_text}\\n\\nReturn a JSON object with keys: summary, classification, structured_data.\"}\n",
        "        ],\n",
        "        \"max_tokens\": 300\n",
        "    }\n",
        "    resp = requests.post(url, headers=headers, data=json.dumps(data))\n",
        "    try:\n",
        "        content = resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "    except Exception:\n",
        "        content = resp.text\n",
        "    entry = {\"conversation\": conv, \"status_code\": resp.status_code, \"response\": content}\n",
        "    results.append(entry)\n",
        "    time.sleep(0.5)\n",
        "\n",
        "with open(\"groq_chat_results.json\", \"w\") as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "results[:1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsxXfgmSph_Y",
        "outputId": "7f9c5e0b-adfc-499b-b49b-ebcb234f6d1e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'conversation': [{'user': 'Hi, I want to cancel my subscription.'},\n",
              "   {'bot': 'Sure, share your subscription ID.'},\n",
              "   {'user': 'SUB6789'},\n",
              "   {'bot': 'Cancellation processed.'}],\n",
              "  'status_code': 200,\n",
              "  'response': 'Here is the processed conversation:\\n\\n```json\\n{\\n  \"summary\": \"The user requested to cancel their subscription and provided their subscription ID (SUB6789). The bot processed the cancellation.\",\\n  \"classification\": \"Customer Support - Subscription Cancellation\",\\n  \"structured_data\": {\\n    \"intent\": \"cancel_subscription\",\\n    \"subscription_id\": \"SUB6789\",\\n    \"outcome\": \"success\"\\n  }\\n}\\n```\\n\\nLet me explain the values:\\n\\n* **summary**: A brief summary of the conversation.\\n* **classification**: A categorization of the conversation topic (Customer Support) and the specific issue (Subscription Cancellation).\\n* **structured_data**: A JSON object containing specific data points extracted from the conversation:\\n\\t+ **intent**: The user\\'s intention (cancel_subscription).\\n\\t+ **subscription_id**: The subscription ID provided by the user (SUB6789).\\n\\t+ **outcome**: The result of the cancellation request (success).'}]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json, re, pathlib\n",
        "\n",
        "raw_text = \"\"\"\n",
        "{\n",
        "  \"conversation\": [\n",
        "    {\"user\": \"Hi, I want to cancel my subscription.\"},\n",
        "    {\"bot\": \"Sure, share your subscription ID.\"},\n",
        "    {\"user\": \"SUB6789\"},\n",
        "    {\"bot\": \"Cancellation processed.\"}\n",
        "  ],\n",
        "  \"status_code\": 200,\n",
        "  \"response\": \"Here is the processed conversation:\\\\n\\\\n```json\\\\n{\\\\n  \\\\\"summary\\\\\": \\\\\"The user requested to cancel their subscription and provided their subscription ID (SUB6789). The bot processed the cancellation.\\\\\",\\\\n  \\\\\"classification\\\\\": \\\\\"Customer Support - Subscription Cancellation\\\\\",\\\\n  \\\\\"structured_data\\\\\": {\\\\n    \\\\\"intent\\\\\": \\\\\"cancel_subscription\\\\\",\\\\n    \\\\\"subscription_id\\\\\": \\\\\"SUB6789\\\\\",\\\\n    \\\\\"outcome\\\\\": \\\\\"success\\\\\"\\\\n  }\\\\n}\\\\n```\"\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "raw = [json.loads(raw_text)]\n"
      ],
      "metadata": {
        "id": "zfHF67tps4YF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for entry in raw:\n",
        "    resp_text = entry.get(\"response\",\"\")\n",
        "    m = re.search(r\"```json\\s*(\\{.*?\\})\\s*```\", resp_text, flags=re.DOTALL)\n",
        "    parsed = {}\n",
        "    if m:\n",
        "        try:\n",
        "            parsed = json.loads(m.group(1))\n",
        "        except Exception:\n",
        "            parsed = {\"error\":\"json_parse_failed\",\"raw\":m.group(1)}\n",
        "    structured = parsed.get(\"structured_data\", parsed)\n",
        "    results.append({\n",
        "        \"conversation\": entry.get(\"conversation\"),\n",
        "        \"status_code\": entry.get(\"status_code\"),\n",
        "        \"structured_data\": structured\n",
        "    })\n",
        "\n",
        "pathlib.Path(\"structured_results.json\").write_text(json.dumps(results, indent=2))\n",
        "print(\"saved\", len(results), \"entries to structured_results.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dJG7HLGtDSU",
        "outputId": "d878f2e3-4b84-4f73-8181-538b0acb28f1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved 1 entries to structured_results.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(open(\"structured_results.json\").read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QG29Mpp1tZ35",
        "outputId": "a7af940a-341e-45fd-c4fc-625241d230f5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"conversation\": [\n",
            "      {\n",
            "        \"user\": \"Hi, I want to cancel my subscription.\"\n",
            "      },\n",
            "      {\n",
            "        \"bot\": \"Sure, share your subscription ID.\"\n",
            "      },\n",
            "      {\n",
            "        \"user\": \"SUB6789\"\n",
            "      },\n",
            "      {\n",
            "        \"bot\": \"Cancellation processed.\"\n",
            "      }\n",
            "    ],\n",
            "    \"status_code\": 200,\n",
            "    \"structured_data\": {\n",
            "      \"intent\": \"cancel_subscription\",\n",
            "      \"subscription_id\": \"SUB6789\",\n",
            "      \"outcome\": \"success\"\n",
            "    }\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "r = Path(\"README.md\").read_text() if Path(\"README.md\").exists() else \"\"\n",
        "if \"structured_results.json\" not in r:\n",
        "    r = r + \"\\n\\nStructured results saved to `structured_results.json` which contains the extracted structured_data for each test conversation.\\n\"\n",
        "    Path(\"README.md\").write_text(r)\n",
        "print(\"README.md updated\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5Io7I-otcKx",
        "outputId": "a3856a9f-2dd4-4c05-a0b1-9e0df860da8a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "README.md updated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"structured_results.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "lS-Sj_8mtm_-",
        "outputId": "03c89e14-c418-4a8d-8ca1-8d0e0de2affe"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9bbfe823-d672-43e4-a518-09613b1cf685\", \"structured_results.json\", 438)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "md = \"\"\"# Groq Chat Processing Notebook\n",
        "\n",
        "## What this notebook does\n",
        "1. Sends sample conversations to Groq OpenAI-compatible API.\n",
        "2. Produces summary, classification, and structured data.\n",
        "3. Runs batch tests and saves outputs to `groq_chat_results.json`.\n",
        "4. Extracts `structured_data` into `structured_results.json`.\n",
        "\n",
        "## How to run\n",
        "1. Set your Groq API key in the `headers` variable.\n",
        "2. Run cells in order.\n",
        "3. Download `structured_results.json` for submission.\n",
        "\n",
        "## Files in repository\n",
        "- `groq_chat_results.json` : raw API responses\n",
        "- `structured_results.json` : extracted structured_data\n",
        "- `README.md` : project description\n",
        "\"\"\"\n",
        "print(md)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMYygzChtqat",
        "outputId": "ab43436c-2663-4263-8dd0-1612e0bd24de"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Groq Chat Processing Notebook\n",
            "\n",
            "## What this notebook does\n",
            "1. Sends sample conversations to Groq OpenAI-compatible API.\n",
            "2. Produces summary, classification, and structured data.\n",
            "3. Runs batch tests and saves outputs to `groq_chat_results.json`.\n",
            "4. Extracts `structured_data` into `structured_results.json`.\n",
            "\n",
            "## How to run\n",
            "1. Set your Groq API key in the `headers` variable.\n",
            "2. Run cells in order.\n",
            "3. Download `structured_results.json` for submission.\n",
            "\n",
            "## Files in repository\n",
            "- `groq_chat_results.json` : raw API responses\n",
            "- `structured_results.json` : extracted structured_data\n",
            "- `README.md` : project description\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"sahil15304@gmail.com\"\n",
        "!git config --global user.name \"sahil15304\"\n",
        "!git init\n",
        "!git add groq_chat_results.json structured_results.json README.md\n",
        "!git commit -m \"Add Groq chat results and structured extraction\"\n",
        "!git branch -M main\n",
        "!git remote add origin https://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@github.com/sahil15304/groq-internship-assignment.git\n",
        "!git push -u origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwmBbzm6twd6",
        "outputId": "a0493d8c-460d-432d-c363-cc3ea8b39270"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reinitialized existing Git repository in /content/.git/\n",
            "On branch main\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31m.config/\u001b[m\n",
            "\t\u001b[31msample_data/\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n",
            "error: remote origin already exists.\n",
            "remote: Repository not found.\n",
            "fatal: repository 'https://github.com/yourusername/your-repo.git/' not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote set-url origin https://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@github.com/sahil15304/groq-internship-assignment.git\n",
        "!git add groq_chat_results.json structured_results.json README.md\n",
        "!git commit -m \"Final commit with results\"\n",
        "!git push -u origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-of4SLewj6z",
        "outputId": "bfeda13a-1e33-4ae2-b14a-516518da357a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31m.config/\u001b[m\n",
            "\t\u001b[31msample_data/\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n",
            "Enumerating objects: 5, done.\n",
            "Counting objects: 100% (5/5), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (5/5), done.\n",
            "Writing objects: 100% (5/5), 1.74 KiB | 1.74 MiB/s, done.\n",
            "Total 5 (delta 1), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (1/1), done.\u001b[K\n",
            "To https://github.com/sahil15304/groq-internship-assignment.git\n",
            " * [new branch]      main -> main\n",
            "Branch 'main' set up to track remote branch 'main' from 'origin'.\n"
          ]
        }
      ]
    }
  ]
}